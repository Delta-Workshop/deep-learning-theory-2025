<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow">
    <title>Deep Learning Theory Workshop 2025</title>


    <style>
        body {
             /*font-family: 'Helvetica', sans-serif; Professional clean font */
            font-family: 'Roboto', sans-serif; /* 使用更为紧凑的 Roboto 字体 */
            margin: 0; 
            padding: 0; 
            background-color: #f4f4f4;
        }


        /* Hero Section */
        .hero {
            position: relative;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            text-align: center;
            background-image: url('tokyo.jpg');
            background-size: cover;
            background-position: center;
        }

        /* Background image wrapper */
        .link {
        	/* text-decoration: underline; */
        }
        
        a.link {
            text-decoration: underline;
            color: #337ab7; /* A shade of blue */
        }

        /* Adding an overlay to the background for transparency */
        .hero::before {
            content: "";
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0, 0.5); 
            z-index: 0; /* Keep the overlay behind the content */
        }

        .hero-text {
            position: relative;
            z-index: 1;
            color: #FFFFFF;
        }

        header h1 {
            font-size: 3.0rem;
            font-weight: bold;
            color: #FFFFFF; /* White color for the heading */
            margin: 0;
            z-index: 1; /* Ensure content is on top of the overlay */
        }

        table.schedule {
            width: 100%;
            border-collapse: collapse;
            text-align: left;
            margin-bottom: 32px;
          }
          table.schedule th,
          table.schedule td {
            border: 1px solid #ddd;
            padding: 8px;
          }
          table.schedule th {
            background: #f5f8fa;
          }
        .subtitle {
            font-size: 1.7rem;
            margin-bottom: 20px;
            color: #00BFFF;
            z-index: 1;
            margin-top: 60px;
        }

        nav {
            position: absolute;
            top: 0;
            width: 100%;
            background: rgba(0, 0, 0, 0.7); /* Transparent black */
            padding: 10px 0;
            text-align: center;
            z-index: 1;
        }

        nav a {
            color: #FFFFFF;
            text-decoration: none;
            margin: 0 15px;
            font-weight: bold;
            font-size: 1.2rem;
        }

        .button {
            background-color: #007bff; /* Blue button */
            color: white;
            padding: 12px 25px;
            border: none;
            cursor: pointer;
            font-size: 1.2rem;
            border-radius: 5px;
            margin-top: 50px;
            z-index: 1;
        }

        .button:hover {
            background-color: #0056b3; /* Darker blue on hover */
        }

        /* Centering content */
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 40px 20px;
        }

    

        .container h2 {
            font-size: 2.8rem;
            font-weight: bold;
            text-align: center;
            margin-bottom: 40px;
            color: #333;
        }

        .container p {
            margin: 10px 0; /* 缩小段落之间的间距 */
            font-size: 17px; /* 将字体大小调整为 16px，更适合长段落 */
            padding: 0; /* 确保左右没有额外内边距 */
            line-height: 1.6;
            text-align: justify; 
            /* margin-bottom: 20px; /*
            color: #333;  
        }

        .container p:last-child {
            margin-left: 0; /* 去除多余左边距 */
            padding-left: 0; /* 去除多余左内边距 */
        }

        .container ol, .container ul {
            text-align: left;
            margin: 10px 0; /* 缩小上下间距 */
            padding-left: 20px;  增加左边距，区分段落 */
        }

        .container ol li {
            margin-bottom: 8px; /* 增加列表项间距，提升层次感 */
            line-height: 1.5; /* 列表行间距 */
        }

        .Description em {
            color: #222; /* 调整斜体文本颜色，使其更加突出 */
        }

/*         .container ol li::marker { */
/*             color: #ffcc00; /* 使用黄色标记符号，使列表项更加显眼 */ 
/*             font-size: 0.8em; /* 增大标记符号的大小 */ 
/*         } */

        .Description section {
            padding: 15px;
            background-color: #f4f4f4; /* 添加浅灰色背景 */
            margin-bottom: 20px; /* 增加每个 section 之间的间距 */
            border-radius: 8px; /* 增加圆角 */
        }


.section-style {
    background-color: #f9f9f9; /* Light grey background */
    padding: 20px; /* Add padding */
    border: 1px solid #ddd; /* Light grey border */
    border-radius: 8px; /* Rounded corners */
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); /* Subtle shadow */
    margin-bottom: 20px; /* Space between sections */

    /* Consistent font size and spacing */
    font-size: 17px; /* Font size */
    line-height: 1.6; /* Line spacing */
    color: #333; /* Text color */
}

/* Consistent spacing for text elements */
.section-style p {
    margin: 10px 0; /* Space between paragraphs */
    padding-left: 0; /* No padding for paragraphs */
    margin-left: 0; /* Ensure paragraphs have no margin on the left */
}
        
.section-style ul, 
.section-style ol {
    margin: 10px 0; /* Space between paragraphs and lists */
/*     padding: 0; /* Increase the padding to move the list further to the right */ 
    margin-left: 0;
    padding-left: 40px; 
}

/* List item spacing */
.section-style ol li,
.section-style ul li {
    margin-bottom: 8px; /* Space between list items */
    line-height: 1.5; /* Line height for list items */
    padding-left: 5px;
}

/* Heading styling */
.section-style h2 {
    font-size: 2.0rem; /* Adjust heading size */
    font-weight: bold;
    color: #333;
    margin-bottom: 20px; /* Space below headings */
}

/* Marker styling for lists */
.section-style ol li::marker, 
.section-style ul li::marker {
/*     color: #ffcc00;  */
    font-size: 1.2em; /* Larger marker size */
}



        /* 增加容器背景色和边框 */
        .Description {
            background-color: #f9f9f9; /* 设置浅灰色背景 */
            padding: 20px; /* 增加内边距 */
            border: 1px solid #ddd; /* 添加浅灰色边框 */
            border-radius: 8px; /* 增加圆角效果 */
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1); /* 添加阴影效果 */
        }  

        /* Overview Section */
        .overview {
            background-color: #f0f4fa;
            padding: 60px 20px;
            text-align: center;
        }

        footer {
            background: #333;
            color: #fff;
            text-align: center;
            padding: 10px;
            margin-top: 20px;
        }

        .organizer-section {
            /*display: flex; 
            flex-wrap: wrap; 
            justify-content: center; 
            gap: 20px; 
            background-color: #333; */
            padding: 20px;
            max-width: 1200px;
            margin: 0 auto;
            text-align: center; /* 确保标题居中 */
        }

      

        .organizer-container {
            display: flex;
            flex-wrap: wrap;
/*             justify-content: center; */
            justify-content: flex-start;
/*             gap: 20px;  */
        }

        
/*         .organizer {
            background-color: #444;
            color: #fff;
            width: calc(33.33% - 40px); 
            text-align: center;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
            margin-bottom: 20px; 
        } */
        .organizer {
            width: calc(33.333% - 20px); /* Adjust width considering margins */
            margin-bottom: 20px;
            margin-right: 30px; /* Space between items */
            text-align: center;
            padding: 20px;
            border-radius: 12px;
            box-sizing: border-box;
        }

        .organizer:nth-child(3n) {
            margin-right: 0; /* Remove right margin from every third item */
        }
        
        /* Ensure images are centered above the names */
        .profile-pic {
            width: 150px;
            height: 150px;
            max-width: 100%;
            object-fit: cover;
            border-radius: 50%;
            margin-bottom: 15px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }
        
        /* Media query for smaller screens to adjust the number of organizers per row */
        @media (max-width: 1024px) {
            .organizer {
                width: calc(50% - 20px); /* Two organizers per row */
            }
            .organizer:nth-child(2n) {
                margin-right: 0; /* Remove right margin from every second item */
            }
            .organizer:nth-child(3n) {
                margin-right: 30px; /* Reset margin for items that were previously affected */
            }
        }
        
        @media (max-width: 600px) {
            .organizer {
                width: 100%; /* One organizer per row */
                margin-right: 0;
            }
        }
        
        .organizer h3 {
            font-size: 1.2rem;
            margin: 10px 0 5px;
            font-weight: bold;
        }
        
        .organizer p {
            font-size: 1rem;
            margin: 0;
            color: #000000;
            text-align: center; /* Center the affiliation text */
        }
    </style>
</head>
<body>

  <div class="hero">
        <nav>
            <a href="#home">Home</a> |
            <a href="#speakers">Speakers</a> |
            <a href="#callen">Registration (English)</a>|
            <a href="#calljp">参加募集 (日本語)</a>|
            <a href="#schedule">Schedule</a> |
            <a href="#organizers">Organizers</a>
        </nav> 

        <div class="hero-text">
            <header>
                <h1>Deep Learning Theory Workshop 2025</h1>
            </header>
            <p class="subtitle">Nihonbashi, Tokyo, August 5-7</p>
<!--             <p class="subtitle">The Thirteenth International Conference on Learning Representations</p> -->
<!--             <p style="color: #FFFFFF;">@Singapore EXPO</p>
            <p style="color: #FFFFFF;">	Mon April 28th</p> -->
           <a href="https://forms.gle/CTWUMdS8ds8kZFPJA" target="_blank">
                <button class="button">In Person Attendance Registration</button>
            </a> 
        </div>
    </div>

    <div class="container">
        <section id="home" class="Description section-style">
            <h2>Description</h2>
            <p>The <strong>Deep Learning Theory Workshop 2025</strong> is organized by the <strong>Deep Learning Theory Team at RIKEN AIP</strong>, and aims to foster in-depth discussions and collaborations at the intersection of deep learning practice and theory.</p>

            <p>This workshop brings together leading researchers from Japan and around the world, including both academic experts and members of our team, to discuss recent advances, open problems, and emerging trends in the theoretical understanding of deep learning.</p>

            <p>While deep learning continues to achieve remarkable success across a wide range of applications, the theoretical foundations behind these breakthroughs are still being actively explored. Questions around generalization, optimization, representation, and robustness remain central to developing a principled understanding of modern deep learning systems.</p>

    <p>We invite contributions and participation from researchers in learning theory, machine learning, statistics, information theory, and related fields, with the goal of building bridges between theoretical analysis and practical advances in deep learning.</p>
</section>

<section id="callen" class="section-style">
  <h2>Call for Participation</h2>

  
<!--   <p>
    <strong>Registration is now open</strong>!
  </p>
 -->
<!--   <p><strong style="color:#d00;">
     Seats for on-site participation are limited, so please register early. 
  </strong></p>
 -->
    
  <h3>Event Details</h3>
  <ul>
    <li><strong>Workshop:</strong> Deep Learning Theory Workshop 2025</li>
    <li><strong>Date:</strong> 5 – 7 August 2025 (Tue – Thu)</li>
    <li><strong>Venue:</strong> RIKEN AIP Nihonbashi Office – Open Space (Tokyo, Japan)</li>
  </ul>

  <h3>Registration</h3>
  <ul>
    <li><strong>On-site Registration:</strong>
        <span style="color:gray;">(Closed)</span>
<!--       <a class="link" href="https://docs.google.com/forms/d/e/1FAIpQLSf2Dvc92Yo8uRiJTqNLgua_nEOZoxs8T5xcC6Z-5tIxE4ByYw/viewform" target="_blank">
        Google Forms
      </a><br>
      Due to building security, <u>pre-registration is mandatory</u> for all on-site attendees. -->
    </li>
    <li><strong>Online Registration:</strong>
      <a class="link" href="https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/185445" target="_blank">
        Doorkeeper
      </a>
    </li>
  </ul>

  <h3>Deadline</h3>
  <ul>
    <li>1 August 2025 (Fri) 23:59 JST</li>
    Registration may close earlier once capacity is reached.
  </ul>

  <h3>Fees</h3>
 <ul>
      <li>Free of charge.</li>
 </ul>

  <h3>Meals &amp; Social Events</h3>
  <ul>
    <li>Aug 5: On-site lunch (dinner for staff only)</li>
    <li>Aug 6: On-site lunch &amp; dinner</li>
    <li>All provided free of charge.</li>
  </ul>

  <h3>Program</h3>
  <ul>
    <li>The latest schedule is available on the
    <a class="link" href="https://delta-workshop.github.io/deep-learning-theory-2025/#schedule" target="_blank">
      Schedule</a>.(Subject to change.)</li>
   </ul>
</section>

<section id="calljp" class="section-style">
  <h2>参加募集</h2>

<!--   <p><strong style="color:#d00;">
      現地参加は席数が限られておりますので、お早めのお申込をお願いします  
  </strong></p> -->

  <h3>概要</h3>
  <ul>
    <li><strong>イベント名：</strong>Deep Learning Theory Workshop 2025</li>
    <li><strong>開催日程：</strong>2025年8月5日（火）〜8月7日（木）</li>
    <li><strong>開催場所：</strong>理研AIP日本橋オフィス オープンスペース</li>
  </ul>

  <h3>参加申込</h3>
  <ul>
    <li><strong>現地参加フォーム：</strong>
        <span style="color:gray;">（受付終了）</span>
<!--       <a class="link" href="https://docs.google.com/forms/d/e/1FAIpQLSf2Dvc92Yo8uRiJTqNLgua_nEOZoxs8T5xcC6Z-5tIxE4ByYw/viewform" target="_blank">
        Google Forms
      </a><br>
      ※ ビル入館登録が必要なため、<u>必ず事前にお申し込みください。</u> -->
    </li>
    <li><strong>オンライン参加登録：</strong>
      <a class="link" href="https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/185445" target="_blank">
        Doorkeeper
      </a>
    </li>
  </ul>

  <h3>参加形式</h3>
  <ul>
    <li>物理会場参加とオンライン参加の 2 種類があります。</li>
    <li>物理会場参加でお申し込みの方は、オンライン参加も可能です。</li>
    <li>オンライン参加でお申し込みの方は、物理会場へはご入場いただけません。</li>
  </ul>

  <h3>受付期間</h3>
   <ul> 
    <li>2025年8月1日（金）23:59 (JST) まで</li>
     ※ 定員に達し次第、締切前でも受付を終了する場合があります。
   </ul>

  <h3>参加費</h3>
    <ul> 
     <li>無料</li>
    </ul>    

  <h3>懇親会・食事</h3>
  <ul>
    <li>8月5日：現地にてランチ（関係者のみディナー）</li>
    <li>8月6日：現地にてランチ・ディナー</li>
    <li>いずれも無料で提供いたします。</li>
  </ul>

  <h3>プログラム</h3>
   <ul>
    <li>最新のプログラムは
    <a class="link" href="https://delta-workshop.github.io/deep-learning-theory-2025/#schedule" target="_blank">
      公式サイトの Schedule
    </a>
    をご覧ください（変更の可能性あり）。</li>
  </ul>
</section>

     


<!-- =========== Schedule（可直接替换你的 section） =========== -->
<section id="schedule" class="section-style">
  <h2>Schedule</h2>

  <!-- ---------- Day 1 ---------- -->
  <h3 style="margin-top: 32px;">Day 1 (Aug 5)</h3>
  <table class="schedule">
    <colgroup>
      <col style="width: 120px" />
      <col style="width: 220px" />
      <col />
    </colgroup>
    <thead>
      <tr>
        <th>Time</th>
        <th>Speaker</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>10:00–10:50</td><td>Taiji Suzuki</td><td>
        <a href="#" class="talk-title" data-abstract="In the first half of this presentation, I will give an overview of our achievements on deep learning theories in the past few years. In particular, I will overview how feature learning affects its predictive performances from several aspects such as representation and optimization. Indeed, if the true function has a sparse structure, deep learning can outperform linear estimators. This observation can be shown even with optimization guarantees by considering shallow neural networks. 
In the second half, I will talk about recent developments of learning theories on modern foundation models such as Transformers and Mixture-of-Experts. In particular, I will show that Transformer can perform test time feature learning for incontext learning and it even achieves the complexity characterized by generative exponent. If time permits, I will show a feature learning theory of training a mixture of experts, in which we show that training together with the router network, MoE can learn an objective even in a difficult situation.">
          Overview of deep learning team achievements, and recent developments on learning theory for modern foundation models
        </a>
      </td></tr>

      <tr><td>11:00–11:40</td><td>Murat Erdogdu</td><td>
        <a href="#" class="talk-title" data-abstract="We study the optimization and sample complexity of gradient-based training of a
two-layer student neural network with quadratic activation function in the
high-dimensional regime, where the input is Gaussian and the response is generated
from a two-layer teacher network with quadratic activation, and power-law decay on
the second-layer coefficients. We provide a sharp analysis of the SGD dynamics in the
feature learning regime, and derive scaling laws for the prediction risk that highlight
the power-law dependencies on the optimization time, sample size, and model width.">
          Learning Quadratic Neural Networks in High Dimensions
        </a>
      </td></tr>

      <tr><td>11:40–13:30</td><td>Working Lunch</td><td></td></tr>

      <tr><td>13:30–14:20</td><td>Fenglei Fan</td><td>
        <a href="#" class="talk-title" data-abstract="In this work, beyond width and depth in a traditional neural network, we augment a neural network with a new dimension called height by inserting links to neurons in the same layer, which gives rise to the notion of height. These links, referred to as intra-layer links, form hierarchical structures that enhance the network's approximation ability (expressivity) without increasing its parameter count. We show that this 3D architecture significantly outperforms conventional 2D networks theoretically and empirically.">
          On Expressivity of Height in Neural Networks
        </a>
      </td></tr>

      <tr><td>14:20–15:10</td><td>Shinho Chewi</td><td>
        <a href="#" class="talk-title" data-abstract="Generative modeling is a form of distribution learning. From this perspective, prior works on sampling guarantees reduce distribution learning, in the form of learning to generate a sample, to score matching. In this work, we reduce other forms of distribution learning (parameter estimation and density estimation) to score matching as well. This leads to new consequences for diffusion models, such as asymptotic efficiency of a DDPM-based parameter estimator and algorithms for Gaussian mixture density estimation, as well as to a general approach for establishing cryptographic hardness results for score estimation. This is joint work with Alkis Kalavasis, Anay Mehrotra, and Omar Montasser.">
          DDPM score matching and distribution learning
        </a>
      </td></tr>

      <tr><td>15:10–15:40</td><td>Coffee Break</td><td></td></tr>

      <tr><td>15:40–16:30</td><td>Mahdi Soltanolkotabi</td><td>
        <a href="#" class="talk-title" data-abstract="Simple first-order methods like Gradient Descent (GD) remain foundational to modern machine learning. Yet, despite their widespread use, our theoretical understanding of the GD trajectory—how and why it works—remains incomplete in both classical and contemporary settings. This talk explores new horizons in understanding the behavior and power of GD across two distinct but connected fronts.
In the first part, we examine the surprising power of a single gradient step in enhancing model reasoning. We focus on test-time training (TTT)—a gradient-based approach that adapts model parameters using individual test instances. We introduce a theoretical framework that reveals how TTT can effectively handle distribution shifts and significantly reduce the data required for in-context learning, shedding light on why such simple methods often outperform expectations.
The second part turns to a more classical optimization setting: learning shallow neural networks with GD. Despite extensive study, even fitting a one-hidden-layer model to basic target functions lacks rigorous performance guarantees. We present a comprehensive analysis of the GD trajectory in this regime, showing how it avoids suboptimal stationary points and converges efficiently to global optima. Our results offer new theoretical foundations for understanding how GD succeeds in the presence of sub-optimal stationary points.">
          One Small Step, One Giant Leap: From Test-Time Tweaks to Global Guarantees
        </a>
      </td></tr>

      <tr><td>16:30–17:30</td><td>Denny Wu</td><td>
        <a href="#" class="talk-title" data-abstract="We study the sample and time complexity of online stochastic gradient descent (SGD) in learning a two-layer neural network with M orthogonal neurons on isotropic Gaussian data. We focus on the challenging “extensive-width” regime M>>1 and allow for large condition number in the second-layer parameters, covering the power-law scaling a_m= m^{-\beta} as a special case. We characterize the SGD dynamics for the training of a student two-layer neural network and identify sharp transition times for the recovery of each signal direction. In the power-law setting, our analysis entails that while the learning of individual teacher neurons exhibits abrupt phase transitions, the juxtaposition of emergent learning curves at different timescales results in a smooth scaling law in the cumulative objective.">
          Learning shallow neural networks in high dimensions: SGD dynamics and scaling laws
        </a>
      </td></tr>

      <tr><td>17:30–18:30</td><td>Poster session</td><td></td></tr>
      <tr><td>18:30–</td><td>Dinner (On your own)</td><td></td></tr>
    </tbody>
  </table>

  <!-- ---------- Day 2 ---------- -->
  <h3 style="margin-top: 32px;">Day 2 (Aug 6)</h3>
  <table class="schedule">
    <colgroup>
      <col style="width: 120px" />
      <col style="width: 220px" />
      <col />
    </colgroup>
    <thead>
      <tr>
        <th>Time</th>
        <th>Speaker</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>10:00–10:50</td><td>Atsushi Nitanda</td><td>
        <a href="#" class="talk-title" data-abstract="Mean-field Langevin dynamics, an interacting particle systems, has an intriguing connection with the noisy gradient descent on infinitely wide two-layer neural networks in the mean-field regime. Therefore, understanding the convergence properties of this dynamics is of great theoretical interest. In this talk, I will present the recent progress on the convergence rate analyses of mean-field Langevin dynamics for optimizing an entropy-regularized convex functional defined over the space of probability distributions, and on the propagation of chaos that quantitatively characterize the particle complexity required for finite-width neural networks to approximate the optimal solution achieved in the mean-field limit.">
          Mean-Field Langevin Dynamics and Propagation of Chaos
        </a>
      </td></tr>

      <tr><td>10:50–11:40</td><td>Yuan Cao</td><td>
        <a href="#" class="talk-title" data-abstract="Transformers have emerged as a dominant force in machine learning, showcasing unprecedented success in a wide range of applications. Their architecture, characterized by self-attention mechanisms, has revolutionized the way models process data. This talk will explore several theoretical case studies on token selection within self-attention mechanisms. We first show how a one-layer transformer model can be successfully trained by gradient descent to perform one-nearest-neighbor prediction in context. Then, we discuss the ability of one-layer transformers to learn variable selection and solve linear regression problems with group sparsity. In addition, we examine the performance of transformers in learning random walks. At the core of these theoretical studies is to analyze how the softmax self-attention can be trained to perform reasonable token selection. Our results show that transformers possess significant compatibility and adaptability with many classical statistical models.">
          Token Selection in Self-Attention Mechanisms: Case Studies and Theoretical Insights
        </a>
      </td></tr>

      <tr><td>11:40–13:30</td><td>Working Lunch</td><td></td></tr>

      <tr><td>13:30–14:20</td><td>Wei Huang</td><td>
        <a href="#" class="talk-title" data-abstract="Vision Transformers (ViTs) have achieved remarkable empirical success, yet their theoretical generalization properties, especially under overfitting, remain unclear. In this talk, we present the first rigorous analysis of benign overfitting in Vision Transformers by characterizing the training dynamics and generalization conditions of a simplified two-layer model trained with gradient descent. Our results identify sharp thresholds—based on the data's signal-to-noise ratio—that separate regimes of benign and harmful overfitting, and are validated by experiments. Additionally, we analyze the optimization behavior of Sign Gradient Descent (SignGD), a surrogate for the widely used Adam optimizer, revealing that both can lead to fast convergence but poor generalization in noisy settings, emphasizing the crucial role of data quality. Our work bridges theoretical and practical perspectives, advancing understanding of transformer optimization and generalization.">
          Understanding Benign Overfitting in Vision Transformers
        </a>
      </td></tr>

      <tr><td>14:20–15:10</td><td>Fanghui Liu</td><td>
        <a href="#" class="talk-title" data-abstract="In this talk, I will illustrate how theory can guide practice, through the lens of low-rank adaptation (LoRA) for fine-tuning large language models. The results  include three folds: 1) Our theoretical results show that LoRA will align to the certain singular subspace of one-step gradient of full fine-tuning. Hence, the subspace alignment and generalization guarantees can be directly achieved by a well-designed spectral initialization strategy for both linear and nonlinear models. 2) Our analysis leads to the LoRA-One algorithm, a theoretically grounded algorithm that achieves significant empirical improvement over vanilla LoRA and its variants on several benchmarks. 3) Our results also clarify some misconceptions in previous algorithm design. Besides, our theory on training dyanmics has its own interest in matrix sensing and deep learning theory. Talk is based on https://arxiv.org/abs/2502.01235 (ICML'25 oral)">
          Bridge theory to practice at scale: One-step gradient suffices for fine-tuning LLMs, provably and efficiently
        </a>
      </td></tr>

      <tr><td>15:10–15:40</td><td>Coffee Break</td><td></td></tr>

      <tr><td>15:40–16:30</td><td>Matus Telgarsky</td><td>
        <a href="#" class="talk-title" data-abstract="TBD">TBD</a>
      </td></tr>

      <tr><td>16:30–17:20</td><td>Takashi Furuya</td><td>
        <a href="#" class="talk-title" data-abstract="Transformers define in-context mappings, which predict new tokens based on a given set of tokens, such as prompts in NLP or patches in vision tasks. In this work, we study their ability to process an arbitrarily large number of context tokens by modeling the context as a probability distribution over tokens, becoming discrete when the number of tokens is finite. Our main result shows that deep transformers are universal approximators of continuous in-context mappings over compact domains. In contrast to previous results, we prove that a transformer with fixed embedding dimensions and a fixed number of attention heads - can achieve any target accuracy, regardless of the number of input tokens, including infinitely many.">
          Transformers are universal in-context learners
        </a>
      </td></tr>

      <tr><td>18:00–</td><td>Working Dinner</td><td></td></tr>
    </tbody>
  </table>

  <!-- ---------- Day 3 ---------- -->
  <h3 style="margin-top: 32px;">Day 3 (Aug 7)</h3>
  <table class="schedule">
    <colgroup>
      <col style="width: 120px" />
      <col style="width: 220px" />
      <col />
    </colgroup>
    <thead>
      <tr>
        <th>Time</th>
        <th>Speaker</th>
        <th>Title</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>10:00–10:50</td><td>Han Bao</td><td>
        <a href="#" class="talk-title" data-abstract="The gradient descent (GD) has been one of the most common optimizers in machine learning. In particular, the loss landscape of a neural network is typically sharpened during the initial phase of training, making the training dynamics hover on the edge of stability. This is beyond our standard understanding of GD convergence in the stable regime where arbitrarily chosen stepsize is sufficiently smaller than the edge of stability. Recently, Wu et al. (COLT2024) have shown that GD converges with arbitrary stepsize under linearly separable logistic regression. Although their analysis hinges on the self-bounding property of the logistic loss, which seems to be a cornerstone to establish a modified descent lemma, our pilot study shows that other loss functions without the self-bounding property can make GD converge with arbitrary stepsize. To further understand what property of a loss function matters in GD, we aim to show arbitrary-stepsize GD convergence for a general loss function based on the framework of Fenchel-Young losses. We essentially leverage the classical perceptron argument to derive the convergence rate for achieving ϵ-optimal loss, which is possible for a majority of Fenchel-Young losses. Among typical loss functions, the Tsallis entropy achieves the GD convergence rate T=Ω(ϵ−1/2), and the R{é}nyi entropy achieves the far better rate T=Ω(ϵ−1/3). We argue that this better rate is possible because of \emph{separation margin} of loss functions, instead of the self-bounding property.">
          Large stepsize logistic regression and beyond
        </a>
      </td></tr>

      <tr><td>10:50–11:40</td><td>Sho Sonoda</td><td>
        <a href="#" class="talk-title" data-abstract="The ridgelet transform has been developed to study neural network parameters, and it can describe the distribution of parameters. Mathematically, it is defined as a pseudo-inverse operator of neural networks. Namely, given a function $f$, and network $NN[\gamma]$ with parameter $\gamma$, the ridgelet transform $R[f]$ for the network $NN$ satisfies the reconstruction formula $NN[R[f]]=f$. For depth-2 fully-connected networks on a Euclidean space, the ridgelet transform has been discovered up to the closed-form expression, thus we could describe how the parameters are distributed. However, for a variety of modern neural network architectures, the closed-form expression has not been known. In this talk, I will introduce a systematic method to induce the generalized neural networks and their corresponding ridgelet transforms from group equivariant functions, and present an application to deep neural networks.">
          Deep Ridgelet Transform: Harmonic Analysis for Deep Neural Network
        </a>
      </td></tr>

      <tr><td>11:40–11:50</td><td>Closing remark</td><td></td></tr>
      <tr><td>12:00–</td><td>Free time</td><td></td></tr>
    </tbody>
  </table>
</section>

<!-- =========== 通用模态框（整页只放一次） =========== -->
<div id="abstract-modal" class="modal" aria-hidden="true">
  <div class="modal-dialog" role="dialog" aria-modal="true" aria-labelledby="abs-title">
    <button class="close-btn" aria-label="Close abstract">&times;</button>
    <h4 id="abs-title" class="modal-title">Abstract</h4>
    <div class="modal-body"></div>
  </div>
</div>

<!-- =========== 内联样式与脚本（整页只放一次，建议置于 </body> 前） =========== -->
<style>
  /* Modal 遮罩与内容 */
  .modal{position:fixed;inset:0;display:none;place-items:center;background:rgba(0,0,0,.45);z-index:9999;}
  .modal.open{display:grid;}
  .modal-dialog{position:relative;max-width:720px;width:calc(100% - 32px);padding:24px;border-radius:10px;background:#fff;box-shadow:0 8px 30px rgba(0,0,0,.25);}
  .modal-title{margin:0 28px 8px 0;font-size:18px}
  .modal-body{line-height:1.6;max-height:60vh;overflow:auto;white-space:pre-wrap;}
  .close-btn{all:unset;position:absolute;top:10px;right:12px;font-size:24px;cursor:pointer;line-height:1;}
  /* 让题目看起来像文本但可点击 */
  .talk-title{color:inherit;text-decoration:none;cursor:pointer}
  .talk-title:hover{text-decoration:underline}
</style>

<script>
  (function(){
    const modal = document.getElementById('abstract-modal');
    const body  = modal.querySelector('.modal-body');
    const closeBtn = modal.querySelector('.close-btn');
    let lastFocused = null;

    // 打开
    function openModal(text){
      lastFocused = document.activeElement;
      body.textContent = text || 'No abstract available.';
      modal.classList.add('open');
      closeBtn.focus();
    }
    // 关闭
    function closeModal(){
      modal.classList.remove('open');
      if (lastFocused && lastFocused.focus) lastFocused.focus();
    }

    // 绑定所有题目
    document.querySelectorAll('.talk-title').forEach(a=>{
      a.addEventListener('click', e=>{
        e.preventDefault();
        openModal(a.dataset.abstract || '');
      });
    });

    // 点击遮罩或 × 关闭
    modal.addEventListener('click', e=>{
      if (e.target === modal || e.target.classList.contains('close-btn')) closeModal();
    });

    // Esc 关闭
    document.addEventListener('keydown', e=>{
      if (e.key === 'Escape' && modal.classList.contains('open')) closeModal();
    });
  })();
</script>





       <section id="speakers" class="organizer-section">
            <h2>Confirmed Speakers [A-Z]</h2>
           <div class="organizer-container">


                <div class="organizer">
                <img src="bao.jpg" alt="Han Bao" class="profile-pic">
                <h3><a class="link" href="https://hermite.jp/" target="_blank">Han Bao</a></h3>
                <p>Associate Professor, Institute of Statistical Mathematics (ISM)</p>
                </div>    

                <div class="organizer">
                <img src="yuancao.png" alt="Yuan Cao" class="profile-pic">
                <h3><a class="link" href="https://yuancaohku.github.io/" target="_blank">Yuan Cao</a></h3>
                <p>Assistant Professor, The University of Hong Kong</p>
                </div>

              <div class="organizer">
                <img src="sinho.jpg" alt="Sinho Chewi" class="profile-pic">
                <h3><a class="link" href="https://chewisinho.github.io/" target="_blank">Sinho Chewi</a></h3>
                <p>Assistant Professor, Yale University</p>
             </div>

              <div class="organizer">
                <img src="murat.jpg" alt="Murat Erdogdu" class="profile-pic">
                <h3><a class="link" href="https://www.cs.toronto.edu/~erdogdu/" target="_blank">Murat Erdogdu</a></h3>
                <p>Assistant Professor, University of Toronto</p>
            </div>  

                <div class="organizer">
                <img src="fengleifang.png" alt="Fenglei Fan" class="profile-pic">
                <h3><a class="link" href="https://www.ds.cityu.edu.hk/people/academic-staff/professor-fenglei-fan" target="_blank">Fenglei Fan</a></h3>
                <p>Assistant Professor, City University of Hong Kong</p>
            </div>   


                <div class="organizer">
                <img src="furuya.jpeg" alt="Takashi Furuya" class="profile-pic">
                <h3><a class="link" href="https://kendb.doshisha.ac.jp/profile/en.77bfc1f47b9eacdc.html" target="_blank">Takashi Furuya</a></h3>
                <p>Assistant Professor, Doshisha University</p>
            </div>   


<!--               <div class="organizer">
                <img src="nikhil.jpg" alt="Nikhil Ghosh" class="profile-pic">
                <h3><a class="link" href="https://nikhil-ghosh-berkeley.github.io/" target="_blank">Nikhil Ghosh</a></h3>
                <p>PhD Candidate, UC Berkeley</p>
            </div>       -->

             <div class="organizer">
                <img src="huangwei.JPG" alt="Wei Huang" class="profile-pic">
                <h3><a class="link" href="https://weihuang05.github.io/" target="_blank">Wei Huang</a></h3>
                <p>Research Scientist, RIKEN AIP</p>
            </div>  

              <div class="organizer">
                <img src="fanghui.jpg" alt="Fanghui Liu" class="profile-pic">
                <h3><a class="link" href="https://www.lfhsgre.org/" target="_blank">Fanghui Liu</a></h3>
                <p>Assistant Professor, University of Warwick</p>
            </div>    



             <div class="organizer">
                <img src="atsushi.png" alt="Atsushi Nitanda" class="profile-pic">
                <h3><a class="link" href="https://sites.google.com/site/atsushinitanda" target="_blank">Atsushi Nitanda</a></h3>
                <p>Principal Research Scientist, A*STAR & NTU </p>
            </div>  

              <div class="organizer">
                <img src="mahdi.jpeg" alt="Mahdi Soltanolkotabi" class="profile-pic">
                <h3><a class="link" href="https://viterbi-web.usc.edu/~soltanol/" target="_blank">Mahdi Soltanolkotabi</a></h3>
                <p>Professor, University of Southern California</p>
            </div>       

               <div class="organizer">
                <img src="sonoda.jpg" alt="Sho Sonoda" class="profile-pic">
                <h3><a class="link" href="https://sites.google.com/view/shosonoda/home" target="_blank">Sho Sonoda</a></h3>
                <p>Senior Research Scientist, RIKEN AIP</p>
            </div>

                

             <div class="organizer">
                <img src="taiji.jpg" alt="Taiji Suzuki" class="profile-pic">
                <h3><a class="link" href="https://ibis.t.u-tokyo.ac.jp/suzuki/" target="_blank">Taiji Suzuki</a></h3>
                <p>Professor, University of Tokyo & RIKEN AIP</p>
            </div>  

                <div class="organizer">
                <img src="matus.jpg" alt="Matus Telgarsky" class="profile-pic">
                <h3><a class="link" href="https://mjt.cs.illinois.edu/" target="_blank">Matus Telgarsky</a></h3>
                <p>Faculty, New York University</p>
            </div>     

             <div class="organizer">
                <img src="denny.jpg" alt="Denny Wu" class="profile-pic">
                <h3><a class="link" href="https://dennywu1.github.io/" target="_blank">Denny Wu</a></h3>
                <p>Faculty Fellow, New York University & Flatiron Institute</p>
            </div>         
     
               
           </div>      
        </section>


        <section id="organizers" class="organizer-section">
            <h2>Organizers</h2>

            <div class="organizer-container">


            <div class="organizer">
                <img src="taiji.jpg" alt="Taiji Suzuki" class="profile-pic">
                <h3><a class="link" href="https://ibis.t.u-tokyo.ac.jp/suzuki/" target="_blank">Taiji Suzuki</a></h3>
                <p>Professor, University of Tokyo & RIKEN AIP</p>
            </div>
        
           
            <div class="organizer">
                <img src="sonoda.jpg" alt="Sho Sonoda" class="profile-pic">
                <h3><a class="link" href="https://sites.google.com/view/shosonoda/home" target="_blank">Sho Sonoda</a></h3>
                <p>Senior Research Scientist, RIKEN AIP</p>
            </div>

             <div class="organizer">
                <img src="huangwei.JPG" alt="Wei Huang" class="profile-pic">
                <h3><a class="link" href="https://weihuang05.github.io/" target="_blank">Wei Huang</a></h3>
                <p>Research Scientist, RIKEN AIP</p>
            </div>

              <div class="organizer">
                <img src="tom.jpg" alt="Tomoya Wakayama" class="profile-pic">
                <h3><a class="link" href="https://tomwaka.github.io/" target="_blank">Tomoya Wakayama</a></h3>
                <p>Postdoctoral Researcher, RIKEN AIP</p>
            </div>          

           
            <div class="organizer">
                <img src="atsushi.png" alt="Atsushi Nitanda" class="profile-pic">
                <h3><a class="link" href="https://sites.google.com/site/atsushinitanda" target="_blank">Atsushi Nitanda</a></h3>
                <p>Principal Research Scientist, A*STAR & NTU </p>
            </div>

            
             <div class="organizer">
                <img src="denny.jpg" alt="Denny Wu" class="profile-pic">
                <h3><a class="link" href="https://dennywu1.github.io/" target="_blank">Denny Wu</a></h3>
                <p>Faculty Fellow, New York University & Flatiron Institute</p>
            </div>        
                
          </div>      
        </section>  

       

        
    </div>

    <footer>
        <p>Contact us at <a style="color:#ffffe0; text-shadow: 0 0 5px #00FF00; font-weight: bold;" href="mailto:delta.workshop.ml@gmail.com">delta.workshop.ml@gmail.com</a></p>

    </footer>
</body>
</html>
